{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from scipy.signal import savgol_filter\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import random\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.set_printoptions(suppress=True) \n",
    "gdf = gpd.read_file(\"PASTIS/metadata.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_COLOR = [2, 1, 0]\n",
    "AGRI_COLOR = [6, 8, 2]\n",
    "EVI2_COLOR = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_and_dates(iloc: int):\n",
    "    def dates_to_days(dates):\n",
    "        dates = [str(date) for date in dates]\n",
    "        date_objs = [datetime.strptime(date, \"%Y%m%d\") for date in dates]\n",
    "        days_diff = [(date - date_objs[0]).days for date in date_objs]\n",
    "        days_diff_array = np.array(days_diff)\n",
    "\n",
    "        return days_diff_array + 1\n",
    "\n",
    "    sample_id = gdf.iloc[iloc].ID_PATCH\n",
    "    dates = dates_to_days(list(gdf.iloc[iloc][\"dates-S2\"].values()))\n",
    "\n",
    "    ts = np.load(f\"PASTIS/DATA_S2/S2_{sample_id}.npy\")\n",
    "    ts = np.moveaxis(ts, 1, -1)\n",
    "\n",
    "    ts = np.clip((ts / 10000) * np.pi, 0, 1)\n",
    "\n",
    "    # # cloud removal\n",
    "    ts[ts[:, :, :, 0] > 0.5] = np.nan  # blue band cut (for cloud detection)\n",
    "    ts[ts[:, :, :, 6] < 0.3] = np.nan  # nir band cut (for cloud shadow)\n",
    "\n",
    "    keeped = np.isnan(ts).mean(axis=(1, 2, 3)) < 0.3\n",
    "    dates = dates[keeped]\n",
    "    ts = ts[keeped]\n",
    "\n",
    "    # first image cloud imputation\n",
    "    first_img_nan_mask = np.isnan(ts[0])\n",
    "    ts[0][first_img_nan_mask] = np.take(\n",
    "        np.nanmean(ts[0], axis=(0, 1)), np.where(first_img_nan_mask)[-1]\n",
    "    )\n",
    "\n",
    "    # other images cloud imputation\n",
    "    for i in range(1, ts.shape[0]):\n",
    "        nan_mask = np.isnan(ts[i])\n",
    "        ts[i][nan_mask] = ts[i - 1][nan_mask]\n",
    "\n",
    "    # smoothing bands\n",
    "    ts = savgol_filter(ts, window_length=11, polyorder=3, axis=0)\n",
    "\n",
    "    # adding EVI2\n",
    "    NIR = ts[:, :, :, 6]\n",
    "    RED = ts[:, :, :, 2]\n",
    "    EVI2 = 2.5 * (NIR - RED) / (NIR + 2 * RED + 1)\n",
    "    ts = np.concatenate((ts, EVI2[:, :, :, np.newaxis]), axis=-1)\n",
    "\n",
    "    # keeping values between 0 and 1\n",
    "    ts = np.clip(ts, 0, 1)\n",
    "\n",
    "    return ts, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_and_dates(ts, dates, color=EVI2_COLOR):\n",
    "    plots_per_row = min(8, np.ceil(ts.shape[0] / 2).astype(int))\n",
    "    rows = np.ceil(ts.shape[0] / plots_per_row).astype(int)\n",
    "    fig, axs = plt.subplots(rows, plots_per_row, figsize=(plots_per_row * 4, rows * 3))\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(plots_per_row):\n",
    "            axs[row, col].set_xticks([])\n",
    "            axs[row, col].set_yticks([])\n",
    "\n",
    "            abs_index = row * plots_per_row + col\n",
    "\n",
    "            if abs_index < ts.shape[0]:\n",
    "                axs[row, col].imshow(ts[abs_index][:, :, color])\n",
    "                axs[row, col].set_title(f\"ts={dates[abs_index]}, EVI2={ts[abs_index, :, :, 10].mean():.2f}\")\n",
    "            else:\n",
    "                fig.delaxes(axs[row, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_ids_to_img(base):\n",
    "    img = np.zeros((*(base.shape),3), dtype=np.uint8)\n",
    "\n",
    "    uniques = np.unique(base)\n",
    "    if len(uniques) < 400:\n",
    "        for unique_id in uniques[(uniques != 0) & (uniques != -1)]:\n",
    "            colors = np.random.randint(40, 220, size=(3), dtype=np.uint8)\n",
    "            white = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "            img[np.where(base==unique_id)] = colors\n",
    "            img[np.where(base==-1)] = white\n",
    "        return img\n",
    "    else: # if there is too many plots, just return a gray image with different contrast\n",
    "        return (base)/(base.max())*255\n",
    "\n",
    "def plot_reference_segmentations(iloc: int, ax=None):\n",
    "    sample_id = gdf.iloc[iloc].ID_PATCH\n",
    "    segmentation = np.load(f\"PASTIS/ANNOTATIONS/ParcelIDs_{sample_id}.npy\")\n",
    "\n",
    "    img = base_ids_to_img(segmentation)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(ts, dates):\n",
    "    def get_single_band_from_indices(ts, indices, band_number):\n",
    "        draw = np.empty((128, 128), dtype=np.float32)\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                draw[i, j] = ts[indices[i, j], i, j, band_number]\n",
    "\n",
    "        return draw\n",
    "\n",
    "    def replace_zeros_with_ones(array):\n",
    "        array[array == 0] = 1\n",
    "        return array\n",
    "\n",
    "    evi2_argmax = np.argmax(ts[:, :, :, EVI2_COLOR], axis=0).squeeze()\n",
    "\n",
    "    vp_dates = dates[evi2_argmax]\n",
    "    evi2_max = np.max(ts[:, :, :, EVI2_COLOR], axis=0).squeeze()\n",
    "    evi2_min = np.min(ts[:, :, :, EVI2_COLOR], axis=0).squeeze()\n",
    "\n",
    "    vp_blue = get_single_band_from_indices(ts, evi2_argmax, 0)\n",
    "    vp_green = get_single_band_from_indices(ts, evi2_argmax, 1)\n",
    "    vp_red = get_single_band_from_indices(ts, evi2_argmax, 2)\n",
    "    vp_re1 = get_single_band_from_indices(ts, evi2_argmax, 3)\n",
    "    vp_re2 = get_single_band_from_indices(ts, evi2_argmax, 4)\n",
    "    vp_re3 = get_single_band_from_indices(ts, evi2_argmax, 5)\n",
    "    vp_nir = get_single_band_from_indices(ts, evi2_argmax, 6)\n",
    "    vp_re4 = get_single_band_from_indices(ts, evi2_argmax, 7)\n",
    "    vp_swir1 = get_single_band_from_indices(ts, evi2_argmax, 8)\n",
    "    vp_swir2 = get_single_band_from_indices(ts, evi2_argmax, 9)\n",
    "\n",
    "    sen_ratio = vp_dates / np.max(vp_dates)\n",
    "\n",
    "    evi2_gain = (evi2_max - ts[0, :, :, EVI2_COLOR].squeeze()) / vp_dates\n",
    "    evi2_loss = (evi2_max - ts[-1, :, :, EVI2_COLOR].squeeze()) / (\n",
    "        replace_zeros_with_ones(np.max(dates) - vp_dates)\n",
    "    )\n",
    "\n",
    "    return np.stack(\n",
    "        [\n",
    "            sen_ratio,\n",
    "            evi2_gain,\n",
    "            evi2_loss,\n",
    "            evi2_max,\n",
    "            evi2_min,\n",
    "            vp_blue,\n",
    "            vp_green,\n",
    "            vp_red,\n",
    "            vp_re1,\n",
    "            vp_re2,\n",
    "            vp_re3,\n",
    "            vp_nir,\n",
    "            vp_re4,\n",
    "            vp_swir1,\n",
    "            vp_swir2,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_euclidean_distance(image: np.ndarray, position1: float, position2: float) -> float:\n",
    "    bands_pixel1 = image[position1]\n",
    "    bands_pixel2 = image[position2]\n",
    "    \n",
    "    distance = np.linalg.norm(bands_pixel1 - bands_pixel2)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def bfs_subplotting(features: np.ndarray, distance_threshold: float = 0.15, min_pixels_to_be_a_region: int = 20) -> np.ndarray:\n",
    "    steps = []\n",
    "\n",
    "    def get_neighbors(i, j):\n",
    "        moves = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "        moves = [(i + x, j + y) for x, y in moves]\n",
    "        moves = list(filter(lambda x: 0 <= x[0] < features.shape[0] and 0 <= x[1] < features.shape[1], moves))\n",
    "        return moves\n",
    "\n",
    "    visited = np.zeros((features.shape[0], features.shape[1]), dtype=bool)\n",
    "    mask = np.zeros((features.shape[0], features.shape[1]), dtype=int)\n",
    "\n",
    "    def bfs_from_a_point(x, y, id, mask):\n",
    "        stack = [(x, y)]\n",
    "        visited[x, y] = True\n",
    "\n",
    "        while stack:\n",
    "            x, y = stack.pop()\n",
    "\n",
    "            for i, j in get_neighbors(x, y):\n",
    "                if not visited[i, j]:\n",
    "                    if calculate_euclidean_distance(features, (x, y), (i, j)) < distance_threshold:\n",
    "                        mask[i, j] = id\n",
    "                        stack.append((i, j))\n",
    "                    visited[i, j] = True\n",
    "\n",
    "        if random.random() < 0.2:\n",
    "            steps.append(mask.copy())\n",
    "\n",
    "    id = 1\n",
    "    while (~visited).any():\n",
    "        indexes = np.where(~visited)\n",
    "        random_index_of_indexes = np.random.randint(0, len(indexes[0]))\n",
    "        bfs_from_a_point(indexes[0][random_index_of_indexes], indexes[1][random_index_of_indexes], id, mask)\n",
    "        id += 1\n",
    "\n",
    "    return base_ids_to_img(mask), base_ids_to_img(np.array(steps))\n",
    "\n",
    "def bfs_less_noise_subplotting(features: np.ndarray, distance_threshold: float = 0.15, min_pixels_to_be_a_region: int = 20) -> np.ndarray:\n",
    "    steps = []\n",
    "\n",
    "    def get_neighbors(i, j):\n",
    "        moves = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "        moves = [(i + x, j + y) for x, y in moves]\n",
    "        moves = list(filter(lambda x: 0 <= x[0] < features.shape[0] and 0 <= x[1] < features.shape[1], moves))\n",
    "        return moves\n",
    "\n",
    "    visited = np.zeros((features.shape[0], features.shape[1]), dtype=bool)\n",
    "    mask = np.zeros((features.shape[0], features.shape[1]), dtype=int)\n",
    "\n",
    "    def bfs_from_a_point(x, y, id, mask):\n",
    "        stack = [(x, y)]\n",
    "        visited[x, y] = True\n",
    "        sub_mask = np.zeros((features.shape[0], features.shape[1]), dtype=int)\n",
    "\n",
    "        while stack:\n",
    "            x, y = stack.pop()\n",
    "\n",
    "            for i, j in get_neighbors(x, y):\n",
    "                if not visited[i, j]:\n",
    "                    if calculate_euclidean_distance(features, (x, y), (i, j)) < distance_threshold:\n",
    "                        sub_mask[i, j] = id\n",
    "                        stack.append((i, j))\n",
    "                    visited[i, j] = True\n",
    "\n",
    "        if (sub_mask==id).sum() > min_pixels_to_be_a_region:\n",
    "            mask += sub_mask\n",
    "            steps.append(mask.copy())\n",
    "\n",
    "    id = 1\n",
    "    while (~visited).any():\n",
    "        indexes = np.where(~visited)\n",
    "        random_index_of_indexes = np.random.randint(0, len(indexes[0]))\n",
    "        bfs_from_a_point(indexes[0][random_index_of_indexes], indexes[1][random_index_of_indexes], id, mask)\n",
    "        id += 1\n",
    "\n",
    "    return base_ids_to_img(mask), base_ids_to_img(np.array(steps))\n",
    "\n",
    "def felzenszwalb_subplotting(graph, cut_quantile=0.7, min_plot_area=40):\n",
    "    def calculate_all_edges(graph):\n",
    "        H, W, _ = graph.shape\n",
    "        diffs = []\n",
    "\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                central_pixel = graph[i, j]\n",
    "                neighboors = []\n",
    "\n",
    "                if i > 0:\n",
    "                    neighboors.append((i-1, j))\n",
    "                    if j > 0:\n",
    "                        neighboors.append((i-1, j-1))\n",
    "                    if j < W-1:\n",
    "                        neighboors.append((i-1, j+1))\n",
    "\n",
    "                if j > 0:\n",
    "                    neighboors.append((i, j-1))\n",
    "                if j < W-1:\n",
    "                    neighboors.append((i, j+1))\n",
    "                \n",
    "                if i < H-1:\n",
    "                    neighboors.append((i+1, j))\n",
    "                    if j > 0:\n",
    "                        neighboors.append((i+1, j-1))\n",
    "                    if j < W-1:\n",
    "                        neighboors.append((i+1, j+1))\n",
    "\n",
    "                for x, y in neighboors:\n",
    "                    neighboor_pixel = graph[x, y]\n",
    "                    diffs.append([i, j, x, y, np.linalg.norm(central_pixel - neighboor_pixel), *(np.abs(central_pixel - neighboor_pixel))])\n",
    "\n",
    "\n",
    "        return np.array(diffs)\n",
    "\n",
    "    steps = []\n",
    "    scaler = StandardScaler()\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "\n",
    "    edges = calculate_all_edges(graph)\n",
    "    scaled_edges = scaler.fit_transform(edges[:, 5:])\n",
    "\n",
    "    kmeans.fit(scaled_edges)\n",
    "\n",
    "    marks = kmeans.predict(scaled_edges)\n",
    "    first_cluster = edges[marks == 0]\n",
    "    second_cluster = edges[marks == 1]\n",
    "\n",
    "    if np.mean(first_cluster[:,4]) < np.mean(second_cluster[:,4]):\n",
    "        first_cluster, second_cluster = second_cluster, first_cluster\n",
    "\n",
    "    new_graph = np.arange(128*128, dtype=np.int16)\n",
    "    np.random.shuffle(new_graph)\n",
    "    new_graph = new_graph.reshape(128,128)\n",
    "\n",
    "    # Filtrando os dados com base na quantile\n",
    "    second_cluster = second_cluster[second_cluster[:, 4] < np.quantile(second_cluster[:, 4], cut_quantile)].copy()\n",
    "    \n",
    "    # Ordenando as linhas do second_cluster com base na quinta coluna\n",
    "    sorted_indices = np.argsort(second_cluster[:, 4])\n",
    "    second_cluster = second_cluster[sorted_indices]\n",
    "\n",
    "    wait = len(second_cluster) // 30\n",
    "    for n, diff in enumerate(second_cluster):\n",
    "        x0,y0,x1,y1 = np.round(diff[:4]).astype(int)\n",
    "        \n",
    "        first_group_id = new_graph[x0, y0]\n",
    "        second_group_id = new_graph[x1, y1]\n",
    "\n",
    "        new_graph[new_graph == first_group_id] = second_group_id\n",
    "\n",
    "        if n % wait == 0:\n",
    "            steps.append(new_graph.copy())\n",
    "\n",
    "    for plot in np.unique(new_graph):\n",
    "        if np.sum(new_graph == plot) < min_plot_area:\n",
    "            new_graph[new_graph == plot] = 0\n",
    "\n",
    "    steps.append(new_graph.copy())\n",
    "\n",
    "\n",
    "    return base_ids_to_img(new_graph), base_ids_to_img(np.array(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_animation(images, title=\"\"):\n",
    "    fig = px.imshow(images, animation_frame=0, color_continuous_scale='plasma', labels={'animation_frame': 'Step'})\n",
    "    fig.update_layout(title=title)\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 2, 5, 2000, 2001\n",
    "\n",
    "iloc = 2000\n",
    "ts, dates = get_images_and_dates(iloc)\n",
    "plot_images_and_dates(ts, dates, RGB_COLOR)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"img/smooth_data.pdf\")\n",
    "features = extract_features(ts, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 5, figsize=(5*4, 3))\n",
    "\n",
    "for aax in ax:\n",
    "    aax.set_xticks([])\n",
    "    aax.set_yticks([])\n",
    "\n",
    "ax[0].imshow(features[:,:,[7,6,5]]*1.3)\n",
    "plot_reference_segmentations(iloc, ax[1])\n",
    "ax[2].imshow(bfs_subplotting(features, 0.13)[0])\n",
    "ax[3].imshow(bfs_less_noise_subplotting(features, 0.12, 20)[0])\n",
    "ax[4].imshow(felzenszwalb_subplotting(features)[0])\n",
    "\n",
    "ax[0].title.set_text(\"RGB from QOL EVI2 Mosaic\")\n",
    "ax[1].title.set_text(\"Reference\")\n",
    "ax[2].title.set_text(\"BFS\")\n",
    "ax[3].title.set_text(\"BFS Less Noise\")\n",
    "ax[4].title.set_text(\"Felzenszwalb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_animation(felzenszwalb_subplotting(features)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import *\n",
    "# import numpy\n",
    "# import maxflow\n",
    "# from PIL import Image\n",
    "# from matplotlib import pyplot as plt\n",
    "# from pylab import *\n",
    "# import cv2\n",
    "\n",
    "# #The function implements graph cut by partitioning a directed graph into two disjoint sets, foreground and background...\n",
    "# def graph(file, # input image\n",
    "# k, # kappa value --> similar pixels have weight close to kappa\n",
    "# s, # Sigma value --> determines how fast the values decay towards zero with increasing dissimilarity.\n",
    "# fore, # foreground area ---> should be input by the user manually.\n",
    "# back): # background area ---> should be input by the user manually.\n",
    "#     I = (Image.open(file).convert('L')) # read image\n",
    "#     If = I.crop(fore) # take a part of the foreground\n",
    "#     Ib = I.crop(back) # take a part of the background\n",
    "#     I,If,Ib = array(I),array(If),array(Ib) # convert all the images to arrays to calculation\n",
    "#     Ifmean,Ibmean = mean(cv2.calcHist([If],[0],None,[256],[0,256])),mean(cv2.calcHist([Ib],[0],None,[256],[0,256])) #Taking the mean of the histogram\n",
    "#     F,B =  ones(shape = I.shape),ones(shape = I.shape) #initalizing the foreground/background probability vector\n",
    "#     Im = I.reshape(-1,1) #Coverting the image array to a vector for ease.\n",
    "#     m,n = I.shape[0],I.shape[1]# copy the size\n",
    "#     g,pic = maxflow.Graph[int](m,n),maxflow.Graph[int]() # define the graph\n",
    "#     structure = np.array([[inf, 0, 0],\n",
    "#                           [inf, 0, 0],\n",
    "#                           [inf, 0, 0]\n",
    "#                          ]) # initializing the structure....\n",
    "#     source,sink,J = m*n,m*n+1,I # Defining the Source and Sink (terminal)nodes.\n",
    "#     nodes,nodeids = g.add_nodes(m*n),pic.add_grid_nodes(J.shape) # Adding non-nodes\n",
    "#     pic.add_grid_edges(nodeids,0),pic.add_grid_tedges(nodeids, J, 255-J)\n",
    "#     gr = pic.maxflow()\n",
    "#     IOut = pic.get_grid_segments(nodeids)\n",
    "#     for i in range(I.shape[0]): # Defining the Probability function....\n",
    "#         for j in range(I.shape[1]):\n",
    "#             F[i,j] = -log(abs(I[i,j] - Ifmean)/(abs(I[i,j] - Ifmean)+abs(I[i,j] - Ibmean))) # Probability of a pixel being foreground\n",
    "#             B[i,j] = -log(abs(I[i,j] - Ibmean)/(abs(I[i,j] - Ibmean)+abs(I[i,j] - Ifmean))) # Probability of a pixel being background\n",
    "#     F,B = F.reshape(-1,1),B.reshape(-1,1) # convertingb  to column vector for ease\n",
    "#     for i in range(Im.shape[0]):\n",
    "#         Im[i] = Im[i] / linalg.norm(Im[i]) # normalizing the input image vector \n",
    "#     w = structure # defining the weight       \n",
    "#     for i in range(m*n):#checking the 4-neighborhood pixels\n",
    "#         ws=(F[i]/(F[i]+B[i])) # source weight\n",
    "#         wt=(B[i]/(F[i]+B[i])) # sink weight\n",
    "#         g.add_tedge(i,ws[0],wt) # edges between pixels and terminal\n",
    "#         if i%n != 0: # for left pixels\n",
    "#             w = k*exp(-(abs(Im[i]-Im[i-1])**2)/s) # the cost function for two pixels\n",
    "#             g.add_edge(i,i-1,w[0],k-w[0]) # edges between two pixels\n",
    "#             '''Explaination of the likelihood function: * used Bayes’ theorem for conditional probabilities\n",
    "#             * The function is constructed by multiplying the individual conditional probabilities of a pixel being either \n",
    "#             foreground or background in order to get the total probability. Then the class with highest probability is selected.\n",
    "#             * for a pixel i in the image:\n",
    "#                                * weight from sink to i:\n",
    "#                                probabilty of i being background/sum of probabilities\n",
    "#                                * weight from source to i:\n",
    "#                                probabilty of i being foreground/sum of probabilities\n",
    "#                                * weight from i to a 4-neighbourhood pixel:\n",
    "#                                 K * e−|Ii−Ij |2 / s\n",
    "#                                  where k and s are parameters that determine hwo close the neighboring pixels are how fast the values\n",
    "#                                  decay towards zero with increasing dissimilarity\n",
    "#             '''\n",
    "#         if (i+1)%n != 0: # for right pixels\n",
    "#             w = k*exp(-(abs(Im[i]-Im[i+1])**2)/s)\n",
    "#             g.add_edge(i,i+1,w[0],k-w[0]) # edges between two pixels\n",
    "#         if i//n != 0: # for top pixels\n",
    "#             w = k*exp(-(abs(Im[i]-Im[i-n])**2)/s)\n",
    "#             g.add_edge(i,i-n,w[0],k-w[0]) # edges between two pixels\n",
    "#         if i//n != m-1: # for bottom pixels\n",
    "#             w = k*exp(-(abs(Im[i]-Im[i+n])**2)/s)\n",
    "#             g.add_edge(i,i+n,w[0],k-w[0]) # edges between two pixels\n",
    "#     I = array(Image.open(file)) # calling the input image again to ensure proper pixel intensities....\n",
    "#     print(\"The maximum flow for %s is %d\"%(file,gr)) # find and print the maxflow\n",
    "#     Iout = ones(shape = nodes.shape)\n",
    "#     for i in range(len(nodes)):\n",
    "#         Iout[i] = g.get_segment(nodes[i]) # calssifying each pixel as either forground or background\n",
    "#     out = 255*ones((I.shape[0],I.shape[1],3)) # initialization for 3d input\n",
    "#     for i in range(I.shape[0]):\n",
    "#         for j in range(I.shape[1]): # converting the True/False to Pixel intensity\n",
    "#             if IOut[i,j]==False:\n",
    "#                 if len(I.shape) == 2:\n",
    "#                     out[i,j,0],out[i,j,1],out[i,j,2] = I[i,j],I[i,j],I[i,j] # foreground for 2d image\n",
    "#                 if len(I.shape) == 3:\n",
    "#                     out[i,j,0],out[i,j,1],out[i,j,2] = I[i,j,0],I[i,j,1],I[i,j,2] # foreground for 3d image\n",
    "#             else:\n",
    "#                 out[i,j,0],out[i,j,1],out[i,j,2] = 1,255,255 # red background \n",
    "#     figure()\n",
    "#     plt.imshow(out,vmin=0,vmax=255) # plot the output image\n",
    "#     plt.show()\n",
    "\n",
    "#     return out\n",
    "\n",
    "# out = graph('input1.jpg',2,100,(225,142,279,185),(7,120,61,163)) #calling the maxflow funtion for input1\n",
    "# #graph('input2.jpg',2,120,(148,105,201,165),(11,12,80,52)) #calling the maxflow funtion for input2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
